---
title: "Confidence Intervals"
author: "Math 271"
date: "3/22/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(magrittr)
library(moderndive)
library(purrr)
library(ggplot2)

```


```{r bootstrap}

bind_group <- function(data, .id="run"){
  data %>% bind_rows(.id=.id) %>% group_by(.data[[.id]], .add=TRUE)
}

bootstrap_means <- rerun(1000, pennies_sample %>% slice_sample(prop=1, replace=TRUE)) %>% 
  bind_group(.id="sample") %>% 
  summarize(mean_year= mean(year))

(mean_hist <- ggplot(bootstrap_means) + aes(x=mean_year) + geom_histogram(center=0, binwidth=1) + 
  xlim(1985, 2005))
```
 

### Three types of CI: two-sided interval, lower-bound, upper-bound

Two-sided interval: Statement: _I'm confident that the population mean is somewhere in this range of numbers._

one-sided intervals: bounds _I'm confident that the population mean is less than some number_. (upper-bound)


probability idea: percentiles (quantiles)  0%-100% vs 0.0 - 1.0

Percentile e.g. if someone is found in the 90th percentile, they are in the top 10%.

A method to represent the upper bound:

```{r}
level = 0.99 

quantile(bootstrap_means$mean_year, level)

mean_hist + geom_vline(xintercept = quantile(bootstrap_means$mean_year, level), col="red")


## this was a side discussion about using max for confidence interval -----------
quantile(bootstrap_means$mean_year, 1.0)
max(bootstrap_means$mean_year)
## ----------
```
When building confidence intervals, we are responsible for developing confidence levels, in the example above the confidence level is set to .99. This means that 99% of the data falls below this point, and 1% of the data falls above this point.

NOTE: The more we increase the upper bound of our confidence interval, the less precise our statements as we put an increasing amount of data on the left side of the upper bound. 

For example:
I'm 99% "confident" that the population mean of penny minting years is less than 2000.2.

"confident" = If I use this method to create an upper bound, then at least 99% of samples will produce a confidence interval that is "correct". 

"correct" = The statement about the real (unknown) population mean is true. 


#### What about a _lower-bound_?

```{r}
level = 0.90 

quantile(bootstrap_means$mean_year, 1 - level)
mean_hist + geom_vline(xintercept = quantile(bootstrap_means$mean_year, 1 - level), col="red")
```
Note: A lower bound confidence level of .90 means 90% of data on right and 10% on the left. A way to do this is by taking the compliment (1 - upper bound) of the upper bound interval of .90.


### How to compute two-sided lookups `(1-level)/2` and `(1+level)/2`

Now: (e.g.) 90% in the middle, and 10% on the "outside". (split it up evenly 5% on each side)

90% confidence level -> 10% outside -> (even split) 5% on bottom and 5% on the top

quantiles to lookup: 0.05 (on bottom) and 0.95 (0.05 on top)

We can do this by making our "level" a vector of 0.05 an 0.95:
```{r}
level = c(0.05, 0.95) 

quantile(bootstrap_means$mean_year, level)
mean_hist + geom_vline(xintercept = quantile(bootstrap_means$mean_year, level), col="red")
```


### Digression: [Anonymous] Functions, pipelines 

Here we are creating a function that is able to compute a confidence interval given a level (e.g. given .90, it will produce .05 and .95):
```{r}

#less efficient way:
ci_probs <- function(level){
lower = (1-level) / 2
upper = (1+level) / 2
c(lower, upper)
}

#simplified efficient method:
ci_probs <- function(level) {
  c(1 + (-1) * level, 
    1 + (+1) * level) / 2
}

#Alternative method:
ci_probs <- function(level){
  (1 + c(-1,1) * level) / 2
}

level=0.9
((level * c(-1,1) ) + 1) / 2

#Another alt. method using magrittr package:
ci_probs <- function(level){
  level %>% multiply_by(c(-1,1)) %>% add(1) %>% divide_by(2)
}
# example showing how using a period (.) with a pipeline creates a function:
ci_probs <- . %>% multiply_by(c(-1,1)) %>% add(1) %>% divide_by(2)


ci_probs(0.90)

ci_probs(0.99)

```

```{r}
quantile(bootstrap_means$mean_year, ci_probs(0.90) ) 

#This method is called the percentile based method.
```

__Function Syntax__
```{r}
foo <- function(x) x^2
foo(3)

#This is an anonymous function and does not need to be assigned to a variable in order to call it (note: brackets are needed to call it):
{function(x) x^2}(5)

function(x) x^2 (5)

{. %>% raise_to_power(2)}(4)

\(x) x^2 ## new anonymous function syntax function replaced with backslash

bar <- \(x) x^2
bar(3)

{\(x) x^2}(6)

```


### Using normal model to get interval

```{r}
ggplot(bootstrap_means) + aes(x=mean_year) + 
  geom_histogram(aes(y=..density..), center=0, binwidth=1) + #Changed count to density on the y-axis
  geom_function(fun=. %>% dnorm(mean=mean(bootstrap_means$mean_year), 
                                sd=sd(bootstrap_means$mean_year)), col="red") + #Using only "dnorm" will give us the standard normal density curve, so we write a function using a pipe that will give us the curve that matches our data. The function slightly modifies dnorm by giving it a specific mean and standard deviation. 
  xlim(1985, 2005)
```

Instead of using the histogram to find our quantiles we will use the density curve.

```{r}
ci_probs(0.95) %>% qnorm(mean=mean(bootstrap_means$mean_year), 
                                sd=sd(bootstrap_means$mean_year))
#This code looks up the quantiles from the "qnorm" data (qnorm for Quantile normal) given a specific mean and standard deviation. In this case, using the bootstrap_means data. 
ci_probs(0.95) %>% quantile(bootstrap_means$mean_year, .)

#By default the pipe function inserts piped data to the first argument in the piped function. By using magrittr we can tell the pipe to place the data in a specific location by using a "." 
level = 0.95
mean_hist + geom_vline(xintercept = ci_probs(level) %>% 
                         qnorm(mean=mean(bootstrap_means$mean_year), 
                               sd=sd(bootstrap_means$mean_year)), 
                       col="purple") + 
  geom_vline(xintercept = quantile(bootstrap_means$mean_year, ci_probs(level)), col="red")

#This graph has the quantiles computed by the normal based method in purple, and the percentile based method in red. Even though they are not the exact same values, they are effectively the same.

#YOU CAN ONLY USE THE NORMAL BASED METHOD IF YOUR DATA FITS A STANDARD BELL CURVE DISTRIBUTION, IN CASES WHERE YOUR DATA DO NOT FIT A BELL CURVE YOU CAN USE THE PERCENTILE BASED METHOD. (Didn't mean to caps lock oops. Sorry!)
```

### Theory-based interval using `t.test`

```{r}
t.test(pennies_sample$year, level=0.95)

#Using a t-test and giving it the original data, you can compute a 95% confidence interval. This can be changed by changing the "level" parameter in the t.test() function.

#The previous approach isn't very "tidy", by using the with() function we can call specific columns in a dataframe. 

with(pennies_sample, t.test(year)) #This code accomplishes the same thing as the previous t.test() function in a "tidy"-er manner. In this case we refer to the columns directly by name instead of using the "$" operator.

#Using the "magrittr" pipe library, instead of using "%>%", we use the exposition "%$%". It tells the function following the exposition to look in the left side for data. 

pennies %$% t.test(year) #This code accomplishes the same thing as the previous two t-tests with less characters. 

bootstrap_means %$% qnorm(ci_probs(0.95), mean=mean(mean_year), sd=sd(mean_year)) #This accomplishes the same thing as Line 183 but uses the exposition instead of the "$" operator. 
```

<div class="bg-warning"> warning </div>


Did people exposed to the "yawn" treatment yawn more or less than the people exposed to the control group of people.

16 people in the control group
34 people in the experimental group
*The sample sizes are not even*

We will look at this question using proportions. In the control group, 25% of people in the group yawned, while in the experimental group, 29.4% of people yawned. We wanna answer the question of whether or not the difference of 4.4% is big. We will use Bootstrapping to answer this question.


### The `mythbusters_yawn` question

### Permutation test






```{r, eval=FALSE, include=FALSE, error=TRUE}
penny_means %>% summarize(p=c(0.025, 0.975), quantile(mean_year,p))

t.test(pennies_sample$year)
with(pennies_sample, t.test(year))
pennies_sample %>% with(t.test(year))
pennies_sample %$% t.test(year)

pennies_sample %>% summarize(mean(year), sd(year), n())

(1 + 0.95)/2
(1 - 0.95)/2

(0.95 * c(-1, 1) + 1)/2

two_tail <- . %>% multiply_by(c(-1,1)) %>% add(1) %>% divide_by(2) 
two_tail <- function(x){(x*c(-1,1) + 1)/2}
two_tail <- \(x)(x*c(-1,1) + 1 )/2
two_tail <- . %>% {(.*c(-1,1) + 1)/2}


two_tail(0.95)

testthat::expect_equal(two_tail(0.95), (0.95 * c(-1, 1) + 1)/2 )


qnorm(two_tail(0.95), mean=1995.44, sd=15.175/sqrt(50))
qnorm(two_tail(0.95)) * (15.175/sqrt(50)) + 1995.44
qt(two_tail(0.95), 49) * (15.175/sqrt(50)) + 1995.44
```

__Stats important side note:__
Robustness: how much does an individual data point impact the data set

The min and maximum values of a data set are not very robust data points.


